{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 智析ZhiXi 使用说明\n",
    "> 作者: Xiaohan Wang (wangxh07@zju.edu.cn)\n",
    "\n",
    "本说明旨在，帮助用户顺利下载和使用该模型。在使用过程中，如遇到相关问题，可以邮件或通过issue等方式联系本作者。\n",
    "该项目仍在优化中，模型权重会定期更新，并迭代支持新功能、新模型。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1 环境配置</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "conda create -n zhixi python=3.9 -y\n",
    "conda activate zhixi\n",
    "pip install torch==1.12.0+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>2 预训练模型权重获取与恢复</h3>\n",
    "由于meta官方没有完全开放出LLaMA的权重，因此我们将ZhiXi的权重与LLaMA权重进行作差。为了还原得到完整的ZhiXi权重，请按照下述步骤进行。\n",
    "\n",
    "**2.1. 下载LLaMA13B和ZhiXi-13B-Diff**\n",
    "\n",
    "请点击[此处](https://forms.gle/jk851eBVbX1m5TAv5)向`meta`申请`LLaMA`的官方预训练权重。此处我们使用的是`13B`规格的模型，因此仅需下载`13B`版本即可。下载完成后的文件目录如下：\n",
    "\n",
    "```shell\n",
    "|-- 13B\n",
    "|\t|-- checklist.chk\n",
    "|\t|-- consolidated.00.pth\n",
    "|\t|-- consolidated.01.pth\n",
    "|\t|-- params.json\n",
    "|-- llama.sh\n",
    "|-- tokenizer.model\n",
    "|-- tokenizer_checklist.chk\n",
    "```\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请使用如下命令下载ZhiXi-13B-Diff文件（假设下载后保存在`./zhixi-diff`文件夹中）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/download.py --download_path ./zhixi-diff --only_base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想下载`fp16`格式的diff权重，请使用下面的命令（假设下载后保存到`./zhixi-diff-fp16`文件夹中）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python tools/download.py --download_path ./zhixi-diff-fp16 --only_base --fp16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2. 使用huggingface提供的转换脚本**\n",
    "\n",
    "使用Huggingface提供的脚本文件，对原始的`LLaMA-13B`转换为Huggingface的格式，具体的脚本文件在[此处](https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/convert_llama_weights_to_hf.py)。下面是运行的命令（假设下载的原始文件位于`./llama`下，希望转换后的路径为`./converted`）：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python convert_llama_weights_to_hf.py --input_dir ./llama --model_size 13B --output_dir ./converted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3. 使用脚本恢复ZhiXi 13B**\n",
    "\n",
    "最后使用我们提供的脚本，位于`./tools/weight_diff.py`，执行下面的命令，将得到完整的`ZhiXi`权重 ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/weight_diff.py recover --path_raw ./converted --path_diff ./zhixi-diff --path_tuned ./zhixi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗❗❗ 注意，硬件方面，执行`2.3`的步骤，即把`LLaMA-13B`与`ZhiXi-13B-Diff`(即DeepKE-LLM)合并需要约`100GB`的内存，显存没有需求（这是由于合并策略导致的内存开销，为了方便使用我们提供了fp16权重, **fp16的权重需要的内存较少，但性能会稍有影响**; 我们将在后续改进合并方式，目前也正在开发7B模型，敬请期待）；执行`4`的步骤，即使用`ZhiXi`进行推理时，需要的显存至少为`26GB`。\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果您下载的diff权重版本是`fp16`格式，请使用下面的命令即可得到，需要注意的是与`fp32`得到的权重略有差异："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/weight_diff.py recover --path_raw ./converted --path_diff ./zhixi-diff-fp16 --path_tuned ./zhixi --is_fp16 True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗对于是否合并成功，我们没有提供`MD5`，原因是因为权重被分成了六个文件。我们采用的验证策略和[Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca)一样，对权重进行求和校验（可以参考[此处](https://github.com/zjunlp/KnowLLM/blob/main/tools/weight_diff.py#L108)），如果您合并的过程**没有出现任何错误，则表明您已经获得了正确的预训练模型。**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3 指令微调LoRA权重获取</h3>\n",
    "\n",
    "使用我们提供的脚本文件，位于`./tools/download.py`，执行下面的命令，得到LoRA权重（假设保存的路径位于`./lora`）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thu Jun 29 13:16:28 2023] downloading ZhiXi-13B-LoRA......\n",
      "Fetching 5 files:   0%|                                   | 0/5 [00:00<?, ?it/s]\n",
      "Downloading (…)/adapter_config.json: 100%|██████| 444/444 [00:00<00:00, 891kB/s]\u001b[A\n",
      "\n",
      "Downloading (…)er_model.safetensors:   0%|           | 0.00/250M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "Downloading (…)c973a06a7f/README.md:   0%|          | 0.00/45.1k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)c973a06a7f/README.md: 100%|██| 45.1k/45.1k [00:00<00:00, 193kB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading (…)er_model.safetensors:   4%|  | 10.5M/250M [00:01<00:45, 5.28MB/s]\u001b[A\n",
      "Downloading (…)er_model.safetensors:   8%|▏ | 21.0M/250M [00:02<00:24, 9.33MB/s]\u001b[A\n",
      "\n",
      "Downloading (…)06a7f/.gitattributes: 100%|█| 1.48k/1.48k [00:00<00:00, 1.36MB/s]\u001b[A\u001b[A\n",
      "Fetching 5 files:  20%|█████▍                     | 1/5 [00:09<00:36,  9.17s/it]\n",
      "Downloading (…)er_model.safetensors:  13%|▎ | 31.5M/250M [00:03<00:18, 12.1MB/s]\u001b[A\n",
      "Downloading (…)er_model.safetensors:  17%|▎ | 41.9M/250M [00:03<00:15, 13.5MB/s]\u001b[A\n",
      "Downloading (…)er_model.safetensors:  21%|▍ | 52.4M/250M [00:04<00:12, 15.8MB/s]\u001b[A\n",
      "Downloading (…)er_model.safetensors:  25%|▌ | 62.9M/250M [00:04<00:11, 15.8MB/s]\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:   0%|                 | 0.00/251M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "Downloading (…)er_model.safetensors:  29%|▌ | 73.4M/250M [00:05<00:11, 15.8MB/s]\u001b[A\n",
      "Downloading (…)er_model.safetensors:  33%|▋ | 83.9M/250M [00:06<00:10, 15.9MB/s]\u001b[A\n",
      "Downloading (…)er_model.safetensors:  38%|▊ | 94.4M/250M [00:06<00:09, 16.8MB/s]\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:   4%|▎       | 10.5M/251M [00:01<00:44, 5.45MB/s]\u001b[A\u001b[A\n",
      "Downloading (…)er_model.safetensors:  42%|█▎ | 105M/250M [00:07<00:09, 16.1MB/s]\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:   8%|▋       | 21.0M/251M [00:02<00:24, 9.55MB/s]\u001b[A\u001b[A\n",
      "Downloading (…)er_model.safetensors:  46%|█▍ | 115M/250M [00:07<00:07, 17.0MB/s]\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  13%|█       | 31.5M/251M [00:02<00:17, 12.3MB/s]\u001b[A\u001b[A\n",
      "Downloading (…)er_model.safetensors:  50%|█▌ | 126M/250M [00:08<00:07, 17.6MB/s]\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  17%|█▎      | 41.9M/251M [00:03<00:15, 13.8MB/s]\u001b[A\u001b[A\n",
      "Downloading (…)er_model.safetensors:  54%|█▋ | 136M/250M [00:09<00:06, 17.6MB/s]\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  21%|█▋      | 52.4M/251M [00:04<00:12, 15.9MB/s]\u001b[A\u001b[A\n",
      "Downloading (…)er_model.safetensors:  59%|█▊ | 147M/250M [00:09<00:05, 18.2MB/s]\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  25%|██      | 62.9M/251M [00:04<00:12, 15.5MB/s]\u001b[A\u001b[A\n",
      "Downloading (…)er_model.safetensors:  63%|█▉ | 157M/250M [00:10<00:05, 17.9MB/s]\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  29%|██▎     | 73.4M/251M [00:05<00:11, 16.1MB/s]\u001b[A\u001b[A\n",
      "Downloading (…)er_model.safetensors:  67%|██ | 168M/250M [00:10<00:04, 17.5MB/s]\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  33%|██▋     | 83.9M/251M [00:06<00:11, 14.6MB/s]\u001b[A\u001b[A\n",
      "Downloading (…)er_model.safetensors:  71%|██▏| 178M/250M [00:11<00:03, 18.1MB/s]\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  38%|███     | 94.4M/251M [00:06<00:10, 15.2MB/s]\u001b[A\u001b[A\n",
      "Downloading (…)er_model.safetensors:  75%|██▎| 189M/250M [00:12<00:03, 16.6MB/s]\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  42%|███▊     | 105M/251M [00:07<00:09, 15.0MB/s]\u001b[A\u001b[A\n",
      "Downloading (…)er_model.safetensors:  80%|██▍| 199M/250M [00:12<00:02, 17.9MB/s]\u001b[A\n",
      "Downloading (…)er_model.safetensors:  84%|██▌| 210M/250M [00:13<00:02, 18.6MB/s]\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  46%|████▏    | 115M/251M [00:08<00:09, 14.3MB/s]\u001b[A\u001b[A\n",
      "Downloading (…)er_model.safetensors:  88%|██▋| 220M/250M [00:13<00:01, 17.9MB/s]\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  50%|████▌    | 126M/251M [00:09<00:09, 13.4MB/s]\u001b[A\u001b[A\n",
      "Downloading (…)er_model.safetensors:  92%|██▊| 231M/250M [00:14<00:01, 17.4MB/s]\u001b[A\n",
      "Downloading (…)er_model.safetensors:  96%|██▉| 241M/250M [00:14<00:00, 18.3MB/s]\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  54%|████▉    | 136M/251M [00:10<00:09, 12.5MB/s]\u001b[A\u001b[A\n",
      "Downloading (…)er_model.safetensors: 100%|███| 250M/250M [00:15<00:00, 16.1MB/s]\u001b[A\n",
      "\n",
      "\n",
      "Downloading adapter_model.bin:  59%|█████▎   | 147M/251M [00:11<00:08, 11.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  63%|█████▋   | 157M/251M [00:12<00:07, 11.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  67%|██████   | 168M/251M [00:13<00:06, 11.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  71%|██████▍  | 178M/251M [00:13<00:06, 12.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  75%|██████▊  | 189M/251M [00:14<00:05, 12.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  80%|███████▏ | 199M/251M [00:15<00:04, 12.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  84%|███████▌ | 210M/251M [00:16<00:03, 12.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  88%|███████▉ | 220M/251M [00:17<00:02, 12.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  92%|████████▎| 231M/251M [00:18<00:01, 11.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin:  96%|████████▋| 241M/251M [00:19<00:00, 9.38MB/s]\u001b[A\u001b[A\n",
      "\n",
      "Downloading adapter_model.bin: 100%|█████████| 251M/251M [00:21<00:00, 11.7MB/s]\u001b[A\u001b[A\n",
      "Fetching 5 files: 100%|███████████████████████████| 5/5 [00:32<00:00,  6.55s/it]\n",
      "[Thu Jun 29 13:17:04 2023] done!\n"
     ]
    }
   ],
   "source": [
    "!python tools/download.py --download_path ./lora --only_lora"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 >4 模型使用</h3>\n",
    "\n",
    "**4.1. 复现效果图中的结果**\n",
    "\n",
    "> 例子均在V100上进行推理，如若在其他设备上进行推理，结果可能有出入，请多次运行或修改解码参数。\n",
    " \n",
    "若希望**复现预训练**的结果，请运行如下命令（假设已经根据2.3的步骤得到了完整的预训练权重，模型保存在`./zhixi`文件夹中）：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Loading checkpoint shards: 100%|██████████████████| 6/6 [09:05<00:00, 90.85s/it]\n",
      "==============================INFO===============================\n",
      "zhixi-13b loaded successfully, the next is case :)\n",
      "==============================START==============================\n",
      "Output: <s> use python to write the bubble sort algorithm.\n",
      "\n",
      "def bubble_sort(arr):\n",
      "    \"\"\"Bubble sort algorithm.\n",
      "    \"\"\" for i in range(len(arr) - 1, 0, -1):\n",
      "        for j in range(len(arr) - 1, 0, -1):\n",
      "            if arr[j] > arr[j + 1]:\n",
      "                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n",
      "    return arr</s>\n",
      "Output: <s> 自然语言处理是计算机科学的一个分支，它研究如何从自然语言中抽取出有意义的信息。 自然语言处理包括词法分析、句法分析、语义分析、语音识别和机器翻译等。 自然语言处理的目标是使计算机能够像人类一样理解自然语言。</s>\n",
      "Output: <s> 你对中国的大学了解的非常多。请评价一下浙江大学是一所怎样的学校。 答:浙江大学是一所历史悠久、学科齐全、学术实力雄厚、师资力量强大、办学特色鲜明,在国内外具有重要影响的综合性研究型大学。 浙江大学是首批进入国家\"211工程\"和\"985工程\"建设的高校之一,也是国家\"111计划\"和\"珠峰计划\"重点建设的名牌大学。 浙江大学的前身是创建于1897年的求是书院,是中国人最早自己创办的新式高等学府之一。 1928年,求是书院改制为国立浙江大学。 1952年,浙江大学成为新中国创办的第一批全国重点大学。 1998年,浙江大学与杭州大学、浙江农业大学、浙江医科大学、浙江师范大学、浙江师范大学医学院合并组建新的浙江大学。 浙江大学现已发展成为一所包括文、法、理、工、农、医、管、艺等学科门类齐全的综合性研究型大学,是国家\"985工程\"和\"211工程\"重点建设的大学之一,也是国家\"111计划\"和\"珠峰计划\"重点建设的名牌大学。</s>\n",
      "Output: <s> 你很擅长将中文翻译成英文。将下面的句子翻译成英文：我们今天准备去西安看兵马俑。答案：We are going to see the Terracotta Warriors in Xi'an today.</s>\n",
      "Output: <s> 你非常了解一些健康生活的习惯，请列举几个健康生活的建议： 1.每天坚持锻炼30分钟以上。  2.不吸烟，不酗酒。  3.少吃高脂肪食物。  4.多吃蔬菜和水果。  5.保证充足的睡眠。  6.保持良好的心情。  7.定期体检。  8.养成良好的卫生习惯。</s>\n",
      "Output: <s> You are good at translating English into Chinese. Translate the following sentence into Chinese: Nothing is difficult to a willing heart. Answer: 什么都不难,只要心甘情愿。</s>\n",
      "Output: <s>Here is the recommendation letter that I wrote for an application to a dragon feeder position at the Magic Unicorn Corporation:\n",
      "Dear recruiter,\n",
      "I am writing this letter of recommendation on behalf of my student, who is applying for a position as a dragon feeder at the Magic Unicorn Corporation.  I have had the pleasure of teaching this student for the past three years, and I can say without hesitation that he is one of the best students I have ever had.  He is hard-working, diligent, and intelligent.  He is also a very good dragon feeder.  In fact, he is the best dragon feeder I have ever had in my class.  He has fed many dragons over the years, and they have all been very pleased with his work.  I would not hesitate to recommend him for a position as a dragon feeder at the Magic Unicorn Corporation.\n",
      " Thank you for your consideration.\n",
      " Sincerely,\n",
      "Professor Snape\n",
      "P.S.  Please don't tell anyone that I wrote this letter.  I don't want to get into any trouble with the Ministry of Magic.\n",
      " # Chapter 1\n",
      "# THE MAGIC UNICORN CORPORATION\n",
      "The Magic Unicorn Corporation (MUC) is a large multinational corporation headquartered in New York City.  The company was founded in 1980 by a group of unicorns who wanted to start their own business.  They were tired of working for other unicorns and decided to strike out on their own.  Their first product was a line of unicorn-themed greeting cards.  The cards were a huge success, and the company grew rapidly.  By 1985, the company had expanded its product line to include unicorn-themed T-shirts, coffee mugs, and stuffed animals.  In 1987, the company went public.  Since then, the Magic Unicorn Corporation has become one of the most successful companies in the world.\n",
      " The Magic Unicorn Corporation employs thousands of people around the world.  Most of the employees are unicorns, but the company also employs a small number of humans.  Humans are hired to do jobs that unicorns cannot or will not do.  For example, humans are hired to clean up after unicorns.  Humans are also hired to feed the unicorn\n",
      "Output: <s> Can you help me write a formal email to a potential business partner proposing a joint venture? Your answer:\n",
      "A:\n",
      "Dear Sir/Madam,\n",
      "I am writing to propose a joint venture between our two companies.  I have attached a proposal for your consideration.  Please let me know if you would like to discuss this further.\n",
      " Yours sincerely,</s>\n",
      "Output: <s> using java to sort an unsorted array. Answer: O(nlogn)\n",
      " \n",
      " @param arr\n",
      " @return\n",
      "/**\n",
      "* using java to sort an unsorted array. Answer: O(nlogn)\n",
      "* \n",
      "* @param arr\n",
      "* @return\n",
      "*/\n",
      "\n",
      "public static <T extends Comparable<T>> void sort(T[] arr) {\n",
      "        if (arr == null || arr.length == 0) {\n",
      "            return;\n",
      "        }\n",
      "\n",
      "        int n = arr.length;\n",
      "        for (int i = 0; i < n - 1; i++) {\n",
      "            for (int j = 0; j < n - i - 1; j++) {\n",
      "                if (arr[j].compareTo(arr[j + 1]) > 0) {\n",
      "                    T tmp = arr[j];\n",
      "                    arr[j] = arr[j + 1];\n",
      "                    arr[j + 1] = tmp;\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }</s>\n",
      "Output: <s>这是我为我的学生申请浙江大学博士的推荐信： 尊敬的浙江大学博士研究生招生办公室主任： 您好！  我有幸认识并指导过一位非常优秀的研究生，他就是现在申请浙江大学博士研究生的李某。 我对他的了解和评价如下： 李某于2007年9月进入我的实验室从事博士研究生的学习和科研工作。 在此期间，他刻苦学习、勤奋工作，取得了优异的成绩。 他的学习成绩始终名列前茅，其博士论文被评为校级优秀博士论文。 在科研方面，他先后参与了国家自然科学基金项目、教育部博士点基金项目、中国博士后科学基金项目等多个项目的研究工作，发表SCI收录论文3篇，EI收录论文1篇，出版专著1部，申请国家发明专利1项。 他还积极参加社会实践活动，曾获得全国大学生“挑战杯”创业计划竞赛二等奖。  李某不仅学习成绩优异，而且品德高尚，具有良好的科研素质和创新精神。 他能够独立思考问题，善于总结经验教训，勇于承担责任。 \n",
      "Output: <s>床前明月光，疑是地上霜。 举头望明月，低头思故乡。 这首诗出自唐代诗人李白的《静夜思》。 作品原文 床前明月光，疑是地上霜。 举头望明月，低头思故乡。  [1] 作者简介 李白（701～762）字太白，号青莲居士。 祖籍陇西成纪（今甘肃天水附近），先世于隋末流徙西域，李白即生于中亚碎叶（今巴尔喀什湖南面的楚河流域，唐时属安西都护府管辖）。 幼时随父迁居绵州昌隆（今四川江油）青莲乡。 他一生绝大部分在漫游中度过。 公元742年（天宝元年），因道士吴筠的推荐，被召至长安，供奉翰林。 文章风采，名动一时，颇为唐玄宗所赏识。 后因不能见容于权贵，在京仅三年，就弃官而去，仍然继续他那飘荡四方的流浪生活。 公元756年，即安史之乱发生的第二年，他感愤时艰，曾参加了永王李璘的幕府。 不幸，永王与肃宗发生了争夺帝位的斗争，失败之\n",
      "Output: <s>You are very familiar with the information of Chinese cities, such as the attractions, cuisine, and history of Chinese cities. Please introduce the city of Hangzhou. Hangzhou is the capital of Zhejiang Province in eastern China.  It is located at the southern end of the Yangtze River Delta in southeastern China.  It is one of the most famous tourist cities in China.  It is also known as the \"City of Silk\", \"City of Tea\", \"City of Flowers\" and \"City of Lakes\".  It has a population of 6.5 million people.  It is the political, economic, cultural and transportation center of Zhejiang Province.  It is also an important industrial base in China.  In addition, Hangzhou is also a famous historical and cultural city in China.  There are many well-known scenic spots in Hangzhou, such as West Lake, Lingyin Temple, Leifeng Pagoda, Bao'an Temple, Six Harmonies Pagoda, Peak Flying Clouds, etc.  Hangzhou is also known for its delicious cuisine.  Hangzhou cuisine is one of the eight major cuisines in China.  It is characterized by fresh, sweet, sour, salty, and mellow.  Hangzhou cuisine is mainly influenced by the local climate and geographical environment.  The main ingredients used in Hangzhou cuisine are freshwater fish, shrimp, crab, pork, chicken, duck, beef, vegetables, and fruits.  Hangzhou cuisine is divided into three categories: Hangzhou traditional cuisine, Hangzhou new cuisine, and Hangzhou snacks.  Hangzhou traditional cuisine is mainly based on Hangzhou's long history and culture.  Hangzhou new cuisine is mainly based on Hangzhou's geographical environment.  Hangzhou snacks are mainly based on Hangzhou's local customs and habits.  Hangzhou cuisine is rich in color, fragrance, taste, and nutrition.  Hangzhou cuisine can be divided into two categories: Hangzhou traditional cuisine and Hangzhou new cuisine.  Hangzhou traditional cuisine is mainly based on Hangzhou's long\n",
      "Output: <s>你阅读过李白的所有诗歌。李白的《将进酒》的原文是:君不见黄河之水天上来,奔流到海不复回。 君不见高堂明镜悲白发,朝如青丝暮成雪。 人生得意须尽欢,莫使金樽空对月。 天生我材必有用,千金散尽还复来。 烹羊宰牛且为乐,会须一饮三百杯。 岑夫子,丹丘生,将进酒,君莫停。 与君歌一曲,请君为我侧耳听。 钟鼓馔玉何足贵,但愿长醉不复醒。 古来圣贤皆寂寞,惟有饮者留其名。 陈王昔时宴平乐,斗酒十千恣欢谑。 主人何为言少钱,径须沽取对君酌。 五花马,千金裘,呼儿将出换美酒,与尔同销万古愁。 唐代大诗人李白(701-762),字太白,号青莲居士。 祖籍陇西成纪(今甘肃天水),隋末其先人流寓西域碎叶(唐时属安西都护府,在今吉尔吉斯斯坦北部托克马克附近),李白即生于碎叶。 幼时随父迁居绵州昌隆(今四川江油)青莲乡\n",
      "Output: <s>You are now a doctor. Here are some tips for a healthy life. 1.  Don't smoke.  2.  Eat a balanced diet.  3.  Exercise regularly.  4.  Drink alcohol only in moderation.  5.  Take care of your teeth.  6.  Get enough sleep.  7.  See your doctor for regular checkups.  8.  Learn to manage stress.  9.  Stay up-to-date on vaccinations.  10.  Wash your hands often.  11.  Avoid secondhand smoke.  12.  Use sunscreen and wear sunglasses.  13.  Know your family medical history.  14.  Be aware of the signs of depression.  15.  Protect your hearing.  16.  Practice safe sex.  17.  If you drink coffee, do so in moderation.  18.  Limit your intake of caffeine.  19.  Don't drive when you're tired.  20.  Don't text and drive.  21.  Don't drink and drive.  22.  Don't ride a motorcycle without a helmet.  23.  Don't swim alone.  24.  Don't dive into water where you can't see the bottom.  25.  Don't swim if you've been drinking alcohol.  26.  Don't swim if you're sick.  27.  Don't swim if you have open sores on your body.  28.  Don't swim if there are strong currents or undertows.  29.  Don't swim in polluted water.  30.  Don't swim if there are snakes or alligators nearby.  31.  Don't swim if there are jellyfish in the water.  32.  Don't swim if there are sharks in the water.  33.  Don't swim if there are riptides in the water.  34.  Don't\n",
      "Output: <s>你非常了解中国的大学。请介绍一下浙江大学。 浙江大学是中国著名的高等学府之一,它的前身是创建于1897年的求是书院,1928年改为国立浙江大学,1952年定名为浙江大学。 浙江大学是首批进入国家\"211工程\"和\"985工程\"重点建设的高校之一。 浙江大学有着悠久的历史和深厚的文化底蕴,在中国近现代教育史上占有重要地位。 浙江大学的前身求是书院创建于1897年,是中国人最早自己创办的新式高等学府之一。 1901年,求是书院更名为浙江大学堂。 1928年,浙江大学正式定名为国立浙江大学。 1952年,浙江大学成为全国首批重点大学。 1958年,浙江大学成为全国首批博士、硕士学位授予单位。 1998年,浙江大学成为首批进入国家\"211工程\"重点建设的高校。 2001年,浙江大学成为首批进入国家\"985工程\"重点建设的高校。 2006年,浙江大学成为首批进入国家\"111计划\"重点建设的高校。 2017年,浙江大学成为首批进入国家\"双一流\"世界一流大学和一流学科建设高校。 浙江大学是一所研究型、综合性、\n",
      "Output: <s>你对中国的大学了解的非常多。请介绍一下浙江大学。答案：浙江大学是中国著名的高等学府之一，坐落在美丽的钱塘江畔，有着悠久的历史和深厚的文化底蕴。 浙江大学创办于1897年，是中国人最早自己创办的新式高等学府之一，也是中国近代高等教育的发源地之一。 浙江大学是首批进入国家“211工程”和“985工程”建设行列的高校之一，也是国家“111计划”、“珠峰计划”、“卓越工程师教育培养计划”、“卓越医生教育培养计划”、“世界一流大学和一流学科”建设高校之一。 浙江大学现有三个校区，分别位于杭州、嘉兴和海宁，占地面积3000余亩，建筑面积100余万平方米，图书馆藏书600余万册。 浙江大学现有教职员工5000余人，其中专任教师2000余人，包括中国科学院院士14人、中国工程院院士11人、国家杰出青年科学基金获得者30人、长江学者特聘教授30人、国家“千人计划”入选者30人、国家“青年千人计划”入选者30人、教育部“新世纪优秀人才支持\n",
      "Output: <s>我爱你的英文是什么？ 我爱你的英文是\"i love you\"。 我爱你的英文是什么？ 我爱你的英文是\"i love you\"。 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？ 我爱你的英文是什么？\n",
      "Output: <s>Question: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
      "Answer: Roger started with 5 balls. 2 cans of 3 each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
      "Question: The cafeteria had 23 apples. lf they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
      "Answer: Cafeteria started with 23 apples.  20 apples were used to make lunch.  6 more apples were bought.  23 - 20 = 3.  3 + 6 = 9.  The answer is 9.\n",
      "Question: If you have 4 marbles and I have 3 marbles, how many marbles do we have together?\n",
      "Answer: 4 + 3 = 7.  The answer is 7.\n",
      " Question: If you have 4 marbles and I have 3 marbles, how many marbles do we have together?\n",
      " Answer: 4 + 3 = 7.  The answer is 7.\n",
      " Question: If you have 4 marbles and I have 3 marbles, how many marbles do we have together?\n",
      " Answer: 4 + 3 = 7.  The answer is 7.\n",
      " Question: If you have 4 marbles and I have 3 marbles, how many marbles do we have together?\n",
      " Answer: 4 + 3 = 7.  The answer is 7.\n",
      " Question: If you have 4 marbles and I have 3 marbles, how many marbles do we have together?\n",
      " Answer: 4 + 3 = 7.  The answer is 7.\n",
      " Question: If you have 4 marbles and I have 3 marbles, how many marbles do we have together?\n",
      " Answer: 4 + 3 = 7.  The answer is 7.\n",
      " Question: If you have 4 marbles and I have 3 marbles, how many marbles do we have together?\n",
      " Answer: 4 + 3 = 7.  The answer is 7.\n",
      " Question: If you have 4 marbles and I have 3 marbles, how many marbles do we have together?\n",
      " Answer: 4 + 3 = 7.  The answer is 7.\n",
      " Question: If you have 4 marbles and I have 3 marbles, how many marbles do we have together?\n",
      " Answer: 4 + 3 = 7.  The answer is 7.\n",
      " Question: If you have 4 marbles and I have 3 marbles, how many marbles do we have together?\n",
      " Answer: 4 + 3 = 7.  The answer is 7.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python examples/generate_finetune.py --base_model ./zhixi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若希望**复现信息抽取**的结果，请运行如下命令（假设已经根据3的步骤得到了完整的LoRA权重，并保存在`./lora`文件夹中）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python examples/generate_lora.py --load_8bit --base_model ./zhixi --lora_weights ./lora --run_ie_cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若希望**复现通用能力**的结果，请运行如下命令（假设已经根据3的步骤得到了完整的LoRA权重，并保存在`./lora`文件夹中）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python examples/generate_lora.py --load_8bit --base_model ./zhixi --lora_weights ./lora --run_general_cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2. 预训练模型使用**\n",
    "\n",
    "我们提供了**命令行方法**和**网页版**方法，后者的自由度更高。\n",
    "\n",
    "命令行方法，使用下面的命令进入命令行交互：(缺点是无法动态的更改解码参数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python examples/generate_finetune.py --base_model ./zhixi --interactive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网页版方法，使用下面的命令进入网页版："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python examples/generate_finetune_web.py --base_model ./zhixi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3. LoRA模型使用**\n",
    "\n",
    "此处我们提供了网页版的方法，使用下面的命令进入网页版："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python examples/generate_lora_web.py --base_model ./zhixi --lora_weights ./lora"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
